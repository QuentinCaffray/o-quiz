# SC02E01 - Conteneurisation Docker

## Menu du jour

- Client
  - présentation du dossier `client`
  - rappels sur les `cors`

- Théorie : Docker
  - Installation de Docker Engine
  - Motivation et intérêt
  - Rappels : images & conteneurs
  - Rappels : DockerHub
  - Rappels : Dockerfile
  - Rappels : Docker compose

- Pratique : Docker
  - CLI : démarrer un conteneur local
  - Dockerfile : créer un Dockerfile (API)
  - Compose : orchestrer des services

- Challenge : Docker
  - Dockerfile : créer un Dockerfile (Client)
  - Compose : ajouter un service


## Svelte & Vite

**Vite** = bundler + serveur de développement
- **bundler** = 
  - l'outil qui permet de transfermer notre code écrit dans une syntaxe propre à Svelte/React/Vue et d'en faire un `bundle` (HTML/CSS/JS statique) -> dossier `dist`
  - `npm run build` -> créer le dossier `dist`
- **dev server** =
  - l'outil qui permet d'avoir du hot reload quand on code en Svelte/React/Vue
  - `npm run dev` -> lance un serveur sur le port 5173

**Svelte** = syntaxe particulier pour écrire des composants frontend
- "template"
- "script"
- "style"

## `SOP` & `CORS`

### Message d'erreur classique

> Access to fetch at 'http://localhost:3000/api/users' from origin 'http://localhost:5173' has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource.

Traduction : le front ne peut pas appelé le back car le back n'a pas autorisé le front

### Explication

Par défaut, les navigateurs appliquement une politique de sécurité appelée la **Same Origin Policy** (`SOP`) : 
- domaine A (ex: `http://localhost:5173`) ne peut pas effectuer de requête vers le domaine B (ex : `http://localhost:3000`) sans autorisation explicite du domaine B. (Domaine = Origin)

Pour autoriser ce type de requête, dit **cross-origin**, alors le domaine B doit ajouter une entête HTTP (Header) : `Access-Control-Allow-Origin` en précisant les domaines qu'il autorise. On assouplie donc la politique SOP par un partage de ressource entre domaines :  **Cross Origin Resource Sharing** (`CORS`)

Pour le SOP : pour éviter par exemple qu'un attaquant (`https://evil-bank.com`) se fasse passer pour un autre services (`https://ma-banque.com`) en présentant les mêmes ressources que celle-ci.


### Quand autoriser les CORS ? 

- Si notre API doit être appelé par notre frontend -> il faut que ton backend autorise ton frontend.
- Si ton API doit être utilisé par des objets connectés -> pas besoin de whitelisté un autre domaine
- Si ton API doit être utilisé par n'importe quel autre front -> on whitelist tout le monde

### Comment ajouter les "CORS" ?

```js
// A la main (peu commun)
app.use((req, res, next) => {
  res.setHeader("Access-Control-Allow-Origin", "*"); // * = tous les domaines
  res.setHeader("Access-Control-Allow-Methods", "GET, POST, PUT, PATCH, DELETE, OPTIONS");
  res.setHeader("Access-Control-Allow-Headers", "Content-Type, Authorization");
  next();
});
```

```js
// Install un module
// npm install cors --prefix api
// npm install --save-dev @types/cors --prefix api

import cors from "cors";

app.use(cors({ origin: "..." }));
```


## Docker : conteneurs et images 

- **Image Docker** :
  - C'est comme un **moule ou un modèle**. Elle contient tout ce qu'il faut pour faire tourner une application : le code, les dépendances, les configurations, le système nécessaire.
  - Elle est **figée et immuable** : on ne la modifie pas directement.

-  **Conteneur Docker** :
  - C'est une **instance en fonctionnement de l'image**. On créé un conteneur à partir d'une image, c'est **l'application qui tourne réellement**, isolée du reste du système.
  - Un conteneur peut être **détruit et recréé à partir de l'image à volonté**.

Analogie :
- L'image <=> la **recette** d’un gâteau.
  - ex : l'image `postgres:17` que l'on trouve sur le DockerHub (repository)
  - ex : c'est l'équivalent du fichier `.iso` ou `.ova` (VM Téléporteur)
- Le conteneur <=> le **gâteau prêt** à être consommé
  - ex : le conteneur `oquiz-database` que l'on créé à partir de l'image et qui contient un mini-système d'exploitation avec Postgres installé
  - ex : c'est l'équivalent de la VM Téléporteur 
    - mais en **version légère** (car **CONTENERISATION** vs. **VIRTUALISATION**) car communique avec le noyau de l'hôte où est installé Docker

## Intérêts de Docker

- `Sécurité` : le conteneur est isolé -> s'il est compromis, alors le système d'exploitation n'est pas touché
- `Scalabilité` : on peut créer autant de conteneur que l'on veut, sur différénte machine, à partir d'une même image
- `Léger` : plus légé qu'une VM
- `Configuration` : on l'a fait une fois pour toutes, puis on instancier autant de conteneur où on veut

### Sans Docker : mettre en prod Oquiz

- Se connecter à la machine de production
- Cloner le dépôt
- Installer Postgres
  - créer une BDD oquiz
- Installer Node
  - installer NVM
- Installer les dépendances
- Lancer manuellement l'application

### Avec Docker : mettre en prod Oquiz

- Se connecter à la machine de production
- Cloner le dépôt
- Installer docker
- Lancer les conteneurs à partir des images


==> Nécessite donc un travail **préparatoire important** : 
- créer les images / réutiliser des images


### Vérifier l'installation de Docker

- Ouvrir un terminal

- `docker -v` ==> ✅ `Docker version X.Y.Z, build xxxxxx`

- `docker run hello-world` ==> ✅ `Hello from Docker!`

## Docker : Command Line Interface (CLI) - Fiche recap'

```bash
# Lister les images téléchargées en local
docker images

# Lister les conteneurs 
docker ps        # Conteneurs actifs (Up)
docker ps -a     # Tous les conteneurs (Up + Exited)

# Créer un conteneur (à partir d'une image existante)
docker run NOM_IMAGE   # l'image sera téléchargée depuis le DockerHub si elle n'est pas présente en local

# Créer un conteneur (avec des options)
docker run
-d                                   # lancer en tâche de fond (daemon)
--name NOM_CONTENEUR                 # choisir le nom du conteneur
-p XXXX:YYYY                         # rediriger un port localhost vers un port dans le conteneur
-v DOSSIER_LOCAL:DOSSIER_CONTENEUR   # monter un dossier local dans un emplacement du conteneur
NOM_IMAGE                            # choix de l'image

# Regarder les logs d'un conteneur
docker logs NOM_ID_CONTENEUR

# Supprimer un conteneur
docker rm ID_OU_NOM_CONTENEUR
docker rm -f ID_OU_NOM_CONTENEUR # supprimer un conteneur encore actif (en forçant)
docker rm -f $(docker ps -a -q)  # supprimer tous les conteneurs (actifs ou inactifs)

# Arrêter un conteneur actif
docker stop ID_OU_NOM_CONTENEUR # arrêt propre
docker kill ID_OU_NOM_CONTENEUR # arrêt net

# Supprimer une image
docker rmi NOM_IMAGE
docker rmi -f $(docker images -q)    # supprimer toutes les images d'un coup

# Faire le ménage
docker system prune
```

### Exemples

```bash
# Conteneur hello-world
docker run hello-world
```

```bash
# Conteneur Ubuntu
docker run ubuntu:jammy   # Ce conteneur s'éteint

# Conteneur Ubuntu (que l'on lance avec une commande)
docker run -it ubuntu:jammy bash  # On est DANS le conteneur avec la commande bash
ls                                # Lister les fichiers dans le conteneur
uname -a                          # Info sur le système d'exploitation
cat /etc/os-release               # Voir la version d'Ubuntu
exit
```

```bash
# Conteneur Apache (~ Nginx) : serveur statique
docker run -d -p 8080:80 --name myserver httpd
# Dans le conteneur, Apache tourne sur le port 80
# Sur notre local, le port 8080 nous redirige vers le conteneur

docker ps                  # on voit notre conteneur
curl http://localhost:8080 # on contacte bien notre serveur

docker exec -it myserver bash  # On exécute la commande bash dans le conteneur (pour prendre la main)
ls
ls htdocs
cat htdocs/index.html            # On trouve le fichier servi par Apache

apt update          # Mettre à jour la liste des packages
apt install nano    # Installer Nano avec APT

nano htdocs/index.html # Modifier le fichier
exit                   # Quitter le conteneur
```

```bash
# Servir notre dossier `dist` du client
docker run -d -p 8080:80 --name myserver httpd
docker exec -it myserver bash
pwd                  # Le dossier s'appelle `/usr/local/apache2/htdocs` : c'est le dossier servi par apache
exit

# Copier le contenu de notre dossier local `client/dist` dans le dossier du conteneur `/usr/local/apache2/htdocs`
docker cp ./client/dist/.   myserver:/usr/local/apache2/htdocs/
```

```bash
# Servir le dossier `dist` du client MAIS sans le copier dans le conteneur
# mais plutôt en le "montant" dans le conteneur
docker run -d -p 8080:80 --name myserver -v ./client/dist:/usr/local/apache2/htdocs httpd

# Monter un dossier, c'est comme faire un "alias"
# Plutot que de lire le "vrai" contenu du dossier htdocs, le conteneur verra le contenu de notre notre dossier `dist`
docker exec -it myserver bash
```


## Et O'quiz dans tout ça ? 

Pour faire tourner O'quiz on a **3 services** :
- **conteneur PostgreSQL (BDD)** --> ce matin
- **conteneur Node.js (API)**    --> cet aprem
- conteneur Nginx (Client)   --> challenge

Objectif de la conteneurisation de O'quiz :
- **UNIQUEMENT pour la production**
  - faciliter la mise en production d'O'quiz demain 
- On pourrait utiliser Docker pour faciliter notre environnement de **developpement**
  - sauf qu'on a déjà tous les outils installé
  - avec hot reload
  - => pas besoin de s'embêter
  - pour développer, on lancera les serveurs à la main (`npm run dev` / `npm run dev`)

## Conteneur BDD PostgreSQL

Ecrire une commande pour lancer un conteneur : 
- basé sur l'image `postgres:18` (latest)
- qui tourne en tâche de fond
- nommé `oquiz-database`
- bindé sur le port `5433` du local

- (lié à Postgres) : choisir un nom pour l'utilisateur par défaut
- (lié à Postgres) : choisir un mot de passe pour cet utilisateur
- (lié à Postgres) : choisir le nom de la BDD par défaut
- (lié à Postgres - optionel) : choisir un emplacement pour nos données

```bash
docker run \                  # Créer un conteneur
-d \                          # Deamon
--name oquiz-database \       # Nom du conteneur
-p 5433:5432 \                # Binding des port
-e POSTGRES_USER=oquiz \      # Nom de l'utilisateur par défaut
-e POSTGRES_PASSWORD=oquiz \  # Nom du mot de passe de cet utilisateur
-e POSTGRES_DB=oquiz \        # Nom de la base de donnée par défaut
-v ./data:/var/lib/postgresql/18/docker   # On monte un dossier "data" à l'intérieur du conteneur (là où Postgres écrit habituellement ces données)
postgres:18                   # Nom et version de l'image (à la fin !)
```

```bash
# Créer le conteneur
docker run -d --name oquiz-database -p 5433:5432 -e POSTGRES_USER=oquiz -e POSTGRES_PASSWORD=oquiz -e POSTGRES_DB=oquiz -v ./data:/var/lib/postgresql/18/docker postgres:18
```

```bash
# Vérifier que la BDD existe bien dans le conteneur
docker ps # Le conteneur est UP

# Vérifier que la BDD oquiz existe bien
docker exec -it oquiz-database psql -U oquiz -d oquiz 
exit 

# Utiliser notre psql "local" pour se connecter dans le conteneur
psql -U oquiz -d oquiz -p 5433 -h localhost
```


## Conteneur Node.js

On a besoin d'un conteneur : 
- `node:24` (LTS)
- copier le dossier api dans le conteneur
- aller dans le conteneur
- installer les dépendances
- build le code TS -> JS
- lancer l'application
- gérer les variables d'environnement

==> Problème : si on supprime le conteneur, il faut tout refaire !
==> Solution : `Dockerfile` :
- créer une **NOUVELLE IMAGE** contenant : 
  - `node:24`
  - notre code applicatif
  - les étapes pour la lancer

**Dockerfile** = partir d'une image et créer la recette permettant de générer un nouveau conteneur prêt à l'emploi (API)


Considération : 
- la majorité du temps, c'est au moment où l'on INSTANCIE l'image (donc à la CREATION du CONTENEUR) que l'on choisi les variables d'environnement


### Créer l'image

- Voir le fichier `api/Dockerfile`

```bash
# Créer l'image
docker build -t oquiz-api ./api`
```

### Créer le conteneur

```bash
docker run -d --name oquiz-api -p 3001:3000 -e DATABASE_URL=postgres://oquiz:oquiz@localhost:5433/oquiz -e ALLOWED_ORIGIN="*" oquiz-api
```

Problème : 
- En lançant cette commande, notre conteneur n'arrive pas à atteindre la base de données (le conteneur BDD oquiz-database)
  - `Error: P1001: Can't reach database server at localhost:5433`
- Pourquoi ? 
  - Car `localhost`, du point de vu du conteneur API, c'est le conteneur API lui-même !
  - Il faudrait donc pointer vers le conteneur `oquiz-database`
- Problème : 
  - Même si on le fait, on serait bloqué car un conteneur est ISOLÉ : il ne peut pas communiquer avec un autre conteneur
- Solution : 
  - Sauf si, on met les deux conteneurs sur le **même réseau** (docker network)

Ici, il faudrait donc : 
- créer un réseau (`oquiz-network`)
- créer le conteneur `oquiz-database` et le placer sur ce réseau
- créer l'image de l'API
- créer le conteneur `oquiz-api` et le placer sur ce réseau
==> ça commence à faire bcp de commande !


Solution : `Docker Compose` 
- on rajoute un fichier de configuration (`compose.yml`) qui va orchestrer le lancement des différents conteneurs 
- _one file to rule them all_

## Docker Compose

C'est un **utilitaire Docker** permettant de lancer plusieurs services (= conteneurs) à l'aide d'une seule commande.

Généralement, on a un fichier à la racine du projet :
- `compose.yml`
- `docker-compose.yml`
- voire même des dérivés en fonction de l'environnement : 
  - `compose-dev.yml`
  - `compose-prod.yml`

Pour lancer les services : 

```bash
# Théorique
docker compose -p NOM_DU_PROJET -f FICHIER_COMPOSE.YML up -d

# Lancer oquiz
docker compose -p oquiz -f docker-compose.yml up -d

# Eteindre oquiz
docker compose -p oquiz down
```

## Debrief de la journée : 

- **Docker** = solution de conteneurisation
- **Image** = recette pour fabriquer des conteneurs
- **Conteneur** = mini système d'exploitation avec les librairies nécessaires pour lancer notre code
- **Compose** = orchestrer plusieurs conteneurs

